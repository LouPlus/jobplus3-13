# /usr/bin/env python3
# -*- coding:utf-8 -*-

import requests
import time
import csv
import random
import json
from lxml import etree

prox = [
        'https://115.226.11.248:808',
        'https://200.159.136.16:53286',
        'https://122.53.183.83:8080',
        'https://124.81.121.62.8080'
        ]

proxies = random.choice(prox)

headers = {
    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:48.0) Gecko/20100101 Firefox/48.0',
    'Accept':'application/json, text/javascript, */*; q=0.01',
    'Host':'www.lagou.com',
    'Origin':'https://www.lagou.com',
    'Referer':'https://www.lagou.com/jobs/list_?city=%E5%85%A8%E5%9B%BD&cl=false&fromSearch=true&labelWords=&suginput=',
    }

cookies = {
    'Cookie': 'user_trace_token=20180125175402-9ea64eb2-4573-4535-b377-f3d84c1877e0;'
    ' _ga=GA1.2.1136621226.1516874047;'
    ' LGUID=20180125175407-af00f512-01b5-11e8-ab94-5254005c3644;' 
    'Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1516937239,1517212801,1517213234,1517213303; _gid=GA1.2.887105809.1517212803; '
    'ab_test_random_num=0; showExpriedIndex=1; '
    'showExpriedCompanyHome=1; showExpriedMyPublish=1; '
    'hasDeliver=0; gate_login_token=ce202aed5d506a0b9599677b6b0dd99d1af1020ce48aeaaa; '
    'index_location_city=%E5%85%A8%E5%9B%BD; '
    'JSESSIONID=ABAAABAACDBABJBDB6BA31AEA9EB69EDBF080637CE2B0ED; '
    'Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1517217240; '
    'LGRID=20180129171357-bc61a837-04d4-11e8-a04b-525400f775ce; '
    '_putrc=452664D9C667AAD1; '
    'login=true; '
    'unick=%E6%8B%89%E5%8B%BE%E7%94%A8%E6%88%B75833; '
    'TG-TRACK-CODE=index_search; gate_login_token=""; '
    'X_HTTP_TOKEN=5aff0cdc856cc5faa670acc39f9347ac; '
    '_gat=1; LGSID=20180129171255-97734b29-04d4-11e8-abd1-5254005c3644; '
    'PRE_UTM=; '
    'PRE_HOST=; '
    'PRE_SITE=; '
    'PRE_LAND=https%3A%2F%2Fwww.lagou.com%2F; '
    'SEARCH_ID=7f11ff6c7e5648f6b79f24ff4709d96c' 
}
    
data = {
    'first': True,
    'pn':1,
}

def get_job(data):
    url = 'https://www.lagou.com/jobs/positionAjax.json?px=new&needAddtionalResult=false&isSchoolJob=0'
    page = requests.post(url=url, cookies=cookies, headers=headers, data=data, proxies=proxies)
    page.encoding = 'utf-8'
    result = json.loads(page.text)
    jobs = result['content']['positionResult']['result']
    for job in jobs:
        companyShortName = job['companyShortName']
        positionId = job['positionId']  # 主页ID
        companyFullName = job['companyFullName']  # 公司全名
        companyLabelList = job['companyLabelList']  # 福利待遇
        companyId = job['companyId']  # 公司ID
        companyLogo = job['companyLogo']  # 公司Logo
        companySize = job['companySize']  # 公司规模
        industryField = job['industryField']
        createTime = job['createTime']  # 发布时间
        district = job['district']  # 地区
        education = job['education']  # 学历要求
        financeStage = job['financeStage']  # 上市否
        firstType = job['firstType']  # 类型
        secondType = job['secondType']  # 类型
        formatCreateTime = job['formatCreateTime']  # 发布时间
        publisherId = job['publisherId']  # 发布人ID
        salary = job['salary']  # 薪资
        workYear = job['workYear']  # 工作年限
        positionName = job['positionName']  #
        jobNature = job['jobNature']  # 全职
        positionAdvantage = job['positionAdvantage']  # 工作福利
        positionLables = job['positionLables']  # 工种
        city = job['city']  # 工作城市
      
        job_detail_url = 'https://www.lagou.com/jobs/{}.html'.format(positionId)
        job_response = requests.get(url=job_detail_url, headers=headers, cookies=cookies, proxies=proxies)
        job_response.encoding = 'utf-8'
        job_tree = etree.HTML(job_response.text)
        job_desc = job_tree.xpath('//*[@id="job_detail"]/dd[2]/div/p/text()')
      # addr = (tree.xpath('//*[@id="job_detail"]//dd[3]/div[1]/a[1]/text()'))[0].replace('\'','')+(tree.xpath('//*[@id="job_detail"]//dd[3]/div[1]/a[2]/text()'))[0].replace('\'','')+((tree.xpath('//*[@id="job_detail"]//dd[3]/div[1]/text()'))[3].replace('\n','')).strip()
        
        company_detail_url = 'https://www.lagou.com/gongsi/{}.html'.format(companyId)
        company_response = requests.get(url=job_detail_url, headers=headers, cookies=cookies, proxies=proxies)
        company_response.encoding = 'utf-8'
        company_tree = etree.HTML(company_response.text)
        company_desc = company_tree.xpath('//*[@id="company_intro"]/div[2]/div/span[1]/p/text()')
        f =  open('../jobplus3-13/datas/jobs.txt', 'a+')
        print('公司全称：%s' % companyFullName, file=f)
        print('公司简称：%s' % companyShortName, file=f)
        print('招聘链接(拉勾网)：%s -> %s' % (companyShortName, job_detail_url), file=f)
      # print('公司ID：%s' % ompanyId, file=f)
        print('公司规模：%s' % companySize, file=f)
        print('职位：%s' % positionName, file=f)
        print('福利待遇：%s' % companyLabelList, file=f)
        print('公司logo：%s' % companyLogo, file=f)
        print('公司阶段：%s' % financeStage, file=f)
        print('职位类型：%s' % firstType, file=f)
        print('薪资待遇：%s' % salary, file=f)
        print('职位诱惑：%s' % positionAdvantage, file=f)
        print('工作城市：%s' % city, file=f)
        print('地区：%s' % district, file=f)
        print('工作类型：%s' % jobNature, file=f)
        print('工作经验：%s' % workYear, file=f)
        print('学历要求：%s' % education, file=f)
        print('发布时间：%s' % createTime, file=f)
        x = ''
        for label in positionLables:
            x += label + ','
        print('技能标签：%s' % x, file=f)
        print('公司类型：%s' % industryField, file=f)
        for job_des in job_desc:
            print(job_des, file=f)
       # print('公司地址：%s' % addr)
        for company_des in company_desc:
            print('公司介绍：%s'% company_desc, file=f)
        print(file=f)

def url(data):
    for x in range(1,50):
        data['pn'] = x
        get_job(data)

if __name__ == '__main__':
    url(data)

